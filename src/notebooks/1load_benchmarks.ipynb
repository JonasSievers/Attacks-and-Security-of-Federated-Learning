{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.modelgenerator import *\n",
    "from utils.modelhandler import *\n",
    "from utils.datahandler import *\n",
    "from utils.attackhandler import *\n",
    "\n",
    "import logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Splitting data into train, validation, and test sets...\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(os.path.normpath(os.path.dirname(os.path.dirname(os.getcwd()))), 'data/3final_data/Final_Energy_dataset.csv')\n",
    "cwd = os.path.normpath(os.getcwd())\n",
    "\n",
    "# User indices based on clusters\n",
    "user_indices = [16, 24] # Cluster 2: [16,24] / Cluster 4: [1, 11, 12, 27] / Cluster 10: [2, 4, 6, 9, 10, 14, 15, 18, 25, 30]\n",
    "\n",
    "# Data processing parameters\n",
    "sequence_length = 25\n",
    "batch_size = 16\n",
    "\n",
    "# Initialize necessary objects\n",
    "dh = Datahandler()\n",
    "m1 = ModelGenerator()\n",
    "mh = Modelhandler()\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"Loading and preparing data...\")\n",
    "df_array = load_and_prepare_data(file_path, user_indices, columns_filter_prefix=\"load\")\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "print(\"Splitting data into train, validation, and test sets...\")\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(df_array, sequence_length, batch_size, dh)\n",
    "X_train_raw = X_train\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()]\n",
    "callbacks = get_callbacks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building:  1  - round  0\n",
      "Building:  1  - round  1\n",
      "Building:  1  - round  2\n",
      "Building:  2  - round  0\n",
      "Building:  2  - round  1\n",
      "Building:  2  - round  2\n",
      "Dictionaries saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Local Learning with NO attack\n",
    "\n",
    "LL_Load_noAttack_aggregated_results, LL_Load_noAttack_all_results  = run_local_learning(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh)\n",
    "\n",
    "save_dictionaries([(\n",
    "    \"LL_Load_noAttack_aggregated_results\", LL_Load_noAttack_aggregated_results), \n",
    "    (\"LL_Load_noAttack_all_results\", LL_Load_noAttack_all_results)], folder_name=\"results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FL: Saved Global models - round  0  (fed_round  0 )\n",
      "FL: Saved Global models - round  0  (fed_round  1 )\n",
      "FL: Saved Global models - round  0  (fed_round  2 )\n",
      "FL: Saved Global models - round  1  (fed_round  0 )\n",
      "FL: Saved Global models - round  1  (fed_round  1 )\n",
      "FL: Saved Global models - round  1  (fed_round  2 )\n",
      "FL: Saved Global models - round  2  (fed_round  0 )\n",
      "FL: Saved Global models - round  2  (fed_round  1 )\n",
      "FL: Saved Global models - round  2  (fed_round  2 )\n",
      "Evaluation: Building:  1  - round  0\n",
      "Evaluation: Building:  1  - round  1\n",
      "Evaluation: Building:  1  - round  2\n",
      "Evaluation: Building:  2  - round  0\n",
      "Evaluation: Building:  2  - round  1\n",
      "Evaluation: Building:  2  - round  2\n",
      "Dictionaries saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Federated Learning with NO attack\n",
    "\n",
    "attack=\"FL_Load_no_attack\"\n",
    "\n",
    "run_federated_training(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "FL_Load_noAttack_aggregated_results, FL_Load_noAttack_all_results = run_federated_local_evaluation(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "\n",
    "save_dictionaries([\n",
    "    (\"FL_Load_noAttack_aggregated_results\", FL_Load_noAttack_aggregated_results), \n",
    "    (\"FL_Load_noAttack_all_results\", FL_Load_noAttack_all_results)], folder_name=\"results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': True, 'result': {'message_id': 287, 'from': {'id': 7071194232, 'is_bot': True, 'first_name': 'Reinforcement Learning', 'username': 'FederatedRL_Bot'}, 'chat': {'id': 5493937056, 'first_name': 'Jonas', 'last_name': 'Sievers', 'username': 'JonasSievers', 'type': 'private'}, 'date': 1723940806, 'text': 'Script .81!'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def send_telegram_message(bot_token, chat_id, message):\n",
    "    \"\"\"Send a message to a Telegram chat via the Bot API.\"\"\"\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "    payload = {\n",
    "        \"chat_id\": chat_id,\n",
    "        \"text\": message,\n",
    "        \"parse_mode\": \"Markdown\"\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Use the function\n",
    "bot_token = os.getenv('TELEGRAM_BOT_TOKEN')\n",
    "chat_id = os.getenv('TELEGRAM_CHAT_ID')\n",
    "message = f\"Script .81!\"\n",
    "\n",
    "result = send_telegram_message(bot_token, chat_id, message)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
