{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.modelgenerator import *\n",
    "from utils.modelhandler import *\n",
    "from utils.datahandler import *\n",
    "from utils.attackhandler import *\n",
    "\n",
    "import logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Splitting data into train, validation, and test sets...\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(os.path.normpath(os.path.dirname(os.path.dirname(os.getcwd()))), 'data/3final_data/Final_Energy_dataset.csv')\n",
    "cwd = os.path.normpath(os.getcwd())\n",
    "\n",
    "# User indices based on clusters\n",
    "user_indices = [16, 24] # Cluster 2: [16,24] / Cluster 4: [1, 11, 12, 27] / Cluster 10: [2, 4, 6, 9, 10, 14, 15, 18, 25, 30]\n",
    "\n",
    "# Data processing parameters\n",
    "sequence_length = 25\n",
    "batch_size = 16\n",
    "\n",
    "# Initialize necessary objects\n",
    "dh = Datahandler()\n",
    "m1 = ModelGenerator()\n",
    "mh = Modelhandler()\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"Loading and preparing data...\")\n",
    "df_array = load_and_prepare_data(file_path, user_indices, columns_filter_prefix=\"load\")\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "print(\"Splitting data into train, validation, and test sets...\")\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(df_array, sequence_length, batch_size, dh)\n",
    "X_train_raw = X_train\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()]\n",
    "callbacks = get_callbacks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisoning Attacks Laplace Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplace DISTRIBUTION - Scale 0.2\n",
    "attack = \"FL_Load_POISON_LapD02\"\n",
    "X_train = X_train_raw.copy()\n",
    "X_train[\"user1\"] = X_train[\"user1\"] + np.random.laplace(loc=0.0, scale=0.2, size=X_train[\"user1\"].shape)\n",
    "\n",
    "plot_impact_of_attack_noise(X_train_raw, X_train, user=\"user1\")\n",
    "\n",
    "#Run Tests\n",
    "run_federated_training(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "aggregated_results, all_results = run_federated_local_evaluation(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "\n",
    "save_dictionaries([\n",
    "    (f\"{attack}_aggregated_results\", aggregated_results), \n",
    "    (f\"{attack}_all_results\", all_results)], folder_name=\"results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplace DISTRIBUTION - Scale 0.4\n",
    "attack = \"FL_Load_POISON_LapD04\"\n",
    "X_train = X_train_raw.copy()\n",
    "X_train[\"user1\"] = X_train[\"user1\"] + np.random.laplace(loc=0.0, scale=0.4, size=X_train[\"user1\"].shape)\n",
    "\n",
    "plot_impact_of_attack_noise(X_train_raw, X_train, user=\"user1\")\n",
    "\n",
    "#Run Tests\n",
    "run_federated_training(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "aggregated_results, all_results = run_federated_local_evaluation(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "\n",
    "save_dictionaries([\n",
    "    (f\"{attack}_aggregated_results\", aggregated_results), \n",
    "    (f\"{attack}_all_results\", all_results)], folder_name=\"results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplace DISTRIBUTION - Scale 0.6\n",
    "attack = \"FL_Load_POISON_LapD06\"\n",
    "X_train = X_train_raw.copy()\n",
    "X_train[\"user1\"] = X_train[\"user1\"] + np.random.laplace(loc=0.0, scale=0.6, size=X_train[\"user1\"].shape)\n",
    "\n",
    "plot_impact_of_attack_noise(X_train_raw, X_train, user=\"user1\")\n",
    "\n",
    "#Run Tests\n",
    "run_federated_training(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "aggregated_results, all_results = run_federated_local_evaluation(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "\n",
    "save_dictionaries([\n",
    "    (f\"{attack}_aggregated_results\", aggregated_results), \n",
    "    (f\"{attack}_all_results\", all_results)], folder_name=\"results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplace DISTRIBUTION - Scale 0.8\n",
    "attack = \"FL_Load_POISON_LapD08\"\n",
    "X_train = X_train_raw.copy()\n",
    "X_train[\"user1\"] = X_train[\"user1\"] + np.random.laplace(loc=0.0, scale=0.8, size=X_train[\"user1\"].shape)\n",
    "\n",
    "plot_impact_of_attack_noise(X_train_raw, X_train, user=\"user1\")\n",
    "\n",
    "#Run Tests\n",
    "run_federated_training(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "aggregated_results, all_results = run_federated_local_evaluation(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "\n",
    "save_dictionaries([\n",
    "    (f\"{attack}_aggregated_results\", aggregated_results), \n",
    "    (f\"{attack}_all_results\", all_results)], folder_name=\"results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplace DISTRIBUTION - Scale 1.0\n",
    "attack = \"FL_Load_POISON_LapD1\"\n",
    "X_train = X_train_raw.copy()\n",
    "X_train[\"user1\"] = X_train[\"user1\"] + np.random.laplace(loc=0.0, scale=1.0, size=X_train[\"user1\"].shape)\n",
    "\n",
    "plot_impact_of_attack_noise(X_train_raw, X_train, user=\"user1\")\n",
    "\n",
    "#Run Tests\n",
    "run_federated_training(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "aggregated_results, all_results = run_federated_local_evaluation(df_array, X_train, y_train, X_val, y_val, X_test, y_test, callbacks, m1, mh, attack, cwd, loss, metrics)\n",
    "\n",
    "save_dictionaries([\n",
    "    (f\"{attack}_aggregated_results\", aggregated_results), \n",
    "    (f\"{attack}_all_results\", all_results)], folder_name=\"results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def send_telegram_message(bot_token, chat_id, message):\n",
    "    \"\"\"Send a message to a Telegram chat via the Bot API.\"\"\"\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "    payload = {\n",
    "        \"chat_id\": chat_id,\n",
    "        \"text\": message,\n",
    "        \"parse_mode\": \"Markdown\"\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Use the function\n",
    "bot_token = os.getenv('TELEGRAM_BOT_TOKEN')\n",
    "chat_id = os.getenv('TELEGRAM_CHAT_ID')\n",
    "message = f\"Script .81!\"\n",
    "\n",
    "result = send_telegram_message(bot_token, chat_id, message)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
