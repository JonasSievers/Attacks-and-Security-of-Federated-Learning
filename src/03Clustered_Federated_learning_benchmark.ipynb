{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from utils.modelgenerator import *\n",
    "from utils.modelhandler import *\n",
    "from utils.datahandler import *\n",
    "\n",
    "#Get data \n",
    "cwd = os.path.normpath(os.path.dirname(os.getcwd()))\n",
    "df = pd.read_csv(cwd+'/data/2feature_engineering_data/df_with_final_features.csv', index_col='Date') #df = pd.read_csv('user5.csv')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "#df = df[['User5', 'temp', 'rhum']]\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "num_users = 30\n",
    "df_array = []\n",
    "for idx in range(num_users):\n",
    "    df_array.append(df[[f'User{idx+1}', 'temp', 'rhum', 'wspd', 'PC1', 'hour sin', 'hour cos', f'User{idx+1}_lag_24hrs']])\n",
    "\n",
    "#df_array[3].head(3)\n",
    "\n",
    "#Train, Validation and Test datasets\n",
    "sequence_length = 25\n",
    "batch_size = 16\n",
    "num_features = df_array[0].shape[1]\n",
    "\n",
    "dh = Datahandler()\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "#Create Train, Validation and Test datasets\n",
    "for idx, df in enumerate(df_array):\n",
    "    n = len(df)\n",
    "    train_df = df[0:int(n*0.7)]\n",
    "    val_df = df[int(n*0.7):int(n*0.9)]\n",
    "    test_df = df[int(n*0.9):]\n",
    "\n",
    "    # Min max sclaing\n",
    "    train_df = dh.min_max_scaling(train_df)\n",
    "    val_df = dh.min_max_scaling(val_df)\n",
    "    test_df = dh.min_max_scaling(test_df)\n",
    "\n",
    "    # Sequencing\n",
    "    train_sequences = dh.create_sequences(train_df, sequence_length)\n",
    "    val_sequences = dh.create_sequences(val_df, sequence_length)\n",
    "    test_sequences = dh.create_sequences(test_df, sequence_length)\n",
    "\n",
    "    #Split into feature and label\n",
    "    X_train[f'user{idx+1}'], y_train[f'user{idx+1}'] = dh.prepare_data(train_sequences, batch_size)\n",
    "    X_val[f'user{idx+1}'], y_val[f'user{idx+1}'] = dh.prepare_data(val_sequences, batch_size)\n",
    "    X_test[f'user{idx+1}'], y_test[f'user{idx+1}'] = dh.prepare_data(test_sequences, batch_size)\n",
    "\n",
    "#General Hyperparameters\n",
    "# #All models\n",
    "horizon = 1\n",
    "max_epochs = 100\n",
    "m1 = ModelGenerator()\n",
    "mh = Modelhandler()\n",
    "\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics=[\n",
    "    tf.keras.metrics.RootMeanSquaredError(), \n",
    "    tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "    tf.keras.metrics.MeanAbsoluteError(),\n",
    "]\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10,mode='min')\n",
    "timing_callback = TimingCallback()\n",
    "custom_callback = CustomCallback()\n",
    "#model_checkpoint = ModelCheckpoint('models/best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "callbacks=[early_stopping, timing_callback, custom_callback] #model_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_weights_with_noise_fedprox(weight_list, clip_threshold=None, noise_scale=0.001, proximal_term=0.1):\n",
    "    avg_grad = list()\n",
    "\n",
    "    for grad_list_tuple in zip(*weight_list):\n",
    "        layer_mean = tf.math.reduce_mean(grad_list_tuple, axis=0)\n",
    "\n",
    "        if clip_threshold is not None:\n",
    "            layer_mean = tf.clip_by_value(layer_mean, -clip_threshold, clip_threshold)\n",
    "\n",
    "        noise = tf.random.normal(shape=layer_mean.shape, mean=0.0, stddev=noise_scale)\n",
    "        noisy_layer_mean = layer_mean + noise\n",
    "\n",
    "        # Add FedProx proximal term\n",
    "        proximal_update = -proximal_term * noisy_layer_mean\n",
    "\n",
    "        avg_grad.append(noisy_layer_mean + proximal_update)\n",
    "\n",
    "    return avg_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning benchmark Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['architecture', 'train_time', 'avg_time_epoch', 'mse','mse_std', 'rmse','rmse_std','mape','mape_std','mae','mae_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([ 2,  7, 11, 23, 24, 30], dtype=int64),\n",
       " 1: array([ 5,  8, 10, 12, 13, 15, 16, 17, 18, 20, 21, 22, 25, 26, 28],\n",
       "       dtype=int64),\n",
       " 2: array([ 1,  3,  4,  6, 19, 27, 29], dtype=int64),\n",
       " 3: array([ 9, 14], dtype=int64)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_clusters = 4\n",
    "y = np.loadtxt(f'../evaluations/clusters_KMeans{num_clusters}_dtw.csv', delimiter=',').astype(int)\n",
    "\n",
    "cluster_users = {i: [] for i in range(num_clusters)}\n",
    "\n",
    "# Iterate through each cluster\n",
    "for cluster_number in range(num_clusters):\n",
    "    users_in_cluster = np.where(y == cluster_number)[0] +1\n",
    "    cluster_users[cluster_number] = users_in_cluster\n",
    "cluster_users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning/models/FL/Dense/global_dense_model/cluster_0/Dense_L3_U16/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning/models/FL/Dense/global_dense_model/cluster_0/Dense_L3_U16/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning/models/FL/Dense/global_dense_model/cluster_1/Dense_L3_U16/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning/models/FL/Dense/global_dense_model/cluster_1/Dense_L3_U16/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning/models/FL/Dense/global_dense_model/cluster_2/Dense_L3_U16/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning/models/FL/Dense/global_dense_model/cluster_2/Dense_L3_U16/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning/models/FL/Dense/global_dense_model/cluster_3/Dense_L3_U16/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning/models/FL/Dense/global_dense_model/cluster_3/Dense_L3_U16/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Federated training round ---------- 1 / 3\n",
      "Cluster 0:\n",
      "User 2\n",
      "User 7\n",
      "User 11\n",
      "User 23\n",
      "User 24\n",
      "User 30\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning/models/FL/Dense/global_dense_model/cluster_0/Dense_L3_U16/FederatedRound1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning/models/FL/Dense/global_dense_model/cluster_0/Dense_L3_U16/FederatedRound1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Cluster 1:\n",
      "User 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m local_model\u001b[38;5;241m.\u001b[39mset_weights(global_model_weights)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#Fit local model to local data\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m histroy, user_results \u001b[38;5;241m=\u001b[39m \u001b[43mmh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_fit_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_index\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_index\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_index\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_index\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_index\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_index\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_index\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marchitecture\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0025\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m#add model weights to list        \u001b[39;00m\n\u001b[0;32m     60\u001b[0m local_model_weights \u001b[38;5;241m=\u001b[39m local_model\u001b[38;5;241m.\u001b[39mget_weights()\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\src\\utils\\modelhandler.py:43\u001b[0m, in \u001b[0;36mModelhandler.compile_fit_evaluate_model\u001b[1;34m(self, model, loss, metrics, X_train, y_train, max_epochs, batch_size, X_val, y_val, X_test, y_test, callbacks, user, hyper, optimizer)\u001b[0m\n\u001b[0;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mloss, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#model = tf.keras.models.load_model('models/best_model.h5')\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#Evaluate the model on test dataset\u001b[39;00m\n\u001b[0;32m     46\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\rs1044\\Documents\\GitHub\\Attacks-and-Security-of-Federated-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Dense MODEL 1 ------------------------------------------------------------------\n",
    "architecture = \"Dense_L3_U16\"\n",
    "\n",
    "dense_units = 16\n",
    "num_layers = 3\n",
    "\n",
    "# Create global models for each cluser (6)\n",
    "for cluster in range(num_clusters):\n",
    "#Build and save global model\n",
    "    global_model = m1.build_dense_model(X_train[f'user{1}'], horizon, num_layers,  dense_units, batch_size)\n",
    "    global_model.save(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster}/{architecture}/FederatedRound{0}\")\n",
    "\n",
    "  \n",
    "federated_rounds = 3\n",
    "for federated_round  in range(federated_rounds):\n",
    "    print(\"Started Federated training round ----------\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "\n",
    "    for cluster_number, users_in_cluster in cluster_users.items():\n",
    "        print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "        #Get global models weights\n",
    "        global_model = keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{architecture}/FederatedRound{federated_round}\", compile=False)\n",
    "        global_model_weights = global_model.get_weights()\n",
    "\n",
    "        #initial list for local model weights\n",
    "        local_model_weight_list = list()\n",
    "\n",
    "\n",
    "        #for idx, user in enumerate(df_array): \n",
    "        for user_index in users_in_cluster:\n",
    "            user_df = df_array[user_index-1]  # Get the user's DataFrame from the array\n",
    "            print(f\"User {user_index}\") \n",
    "                      \n",
    "            #build and compile local model X_train, batch_size, horizon, dense_units,  expert_units, num_experts, m1\n",
    "            local_model = m1.build_dense_model(X_train[f'user{user_index}'], horizon, num_layers,  dense_units, batch_size)\n",
    "            local_model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.0006), metrics=metrics)\n",
    "\n",
    "            #set local model weight to the weight of the global model\n",
    "            local_model.set_weights(global_model_weights)\n",
    "            \n",
    "            #Fit local model to local data\n",
    "            histroy, user_results = mh.compile_fit_evaluate_model(\n",
    "                model=local_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0025),\n",
    "            )\n",
    "            #add model weights to list        \n",
    "            local_model_weights = local_model.get_weights()\n",
    "            local_model_weight_list.append(local_model_weights)\n",
    "        \n",
    "            #clear session to free memory after each communication round\n",
    "            K.clear_session()\n",
    "        \n",
    "        #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "        average_weights = avg_weights_with_noise_fedprox(local_model_weight_list)\n",
    "        #update global model \n",
    "        global_model.set_weights(average_weights)\n",
    "        #Save global models\n",
    "        global_model.save(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{architecture}/FederatedRound{federated_round+1}\")\n",
    "        print(\"Saved Global models\")\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "\n",
    "for cluster_number, users_in_cluster in cluster_users.items():\n",
    "    print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "    #Get global models weights\n",
    "    global_model = tf.keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "\n",
    "    #for idx, user in enumerate(df_array): \n",
    "    for user_index in users_in_cluster:\n",
    "        print(\"User: \", user_index)\n",
    "        for round in range(3):\n",
    "            global_model = tf.keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "            local_model = m1.build_dense_model(X_train[f'user{user_index}'], horizon, num_layers,  dense_units, batch_size)\n",
    "            local_model.set_weights(global_model.get_weights())\n",
    "            \n",
    "            histroy, user_results = mh.compile_fit_evaluate_model(\n",
    "                model=local_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = 1, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0025)\n",
    "            )\n",
    "            # Add the 'architecture' column from dense_user_results to dense_results\n",
    "            all_results = pd.merge(all_results, user_results, how='outer')  \n",
    "\n",
    "for idx in range(len(df_array)):\n",
    "    new_row = {\n",
    "        'architecture': architecture,\n",
    "        'train_time': all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"train_time\"].mean(), \n",
    "        'avg_time_epoch' : all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"avg_time_epoch\"].mean(),\n",
    "        'mse': all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].mean(),\n",
    "        'mse_std' : all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].std(),\n",
    "        'rmse': all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].mean(),\n",
    "        'rmse_std' : all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].std(),\n",
    "        'mape': all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].mean(),\n",
    "        'mape_std' : all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].std(),\n",
    "        'mae': all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].mean(),\n",
    "        'mae_std' : all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].std(),\n",
    "    }\n",
    "    results.loc[len(results)] = new_row\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018702405634232692\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architecture</th>\n",
       "      <th>train_time</th>\n",
       "      <th>avg_time_epoch</th>\n",
       "      <th>mse</th>\n",
       "      <th>mse_std</th>\n",
       "      <th>rmse</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>mape</th>\n",
       "      <th>mape_std</th>\n",
       "      <th>mae</th>\n",
       "      <th>mae_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.940380</td>\n",
       "      <td>0.861906</td>\n",
       "      <td>0.034988</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.187027</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>1.253973e+05</td>\n",
       "      <td>46866.889580</td>\n",
       "      <td>0.134483</td>\n",
       "      <td>0.008541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.915245</td>\n",
       "      <td>0.844485</td>\n",
       "      <td>0.018157</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.134733</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>1.812737e+05</td>\n",
       "      <td>40845.543470</td>\n",
       "      <td>0.078444</td>\n",
       "      <td>0.002914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.912691</td>\n",
       "      <td>0.841930</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.140459</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>6.088697e+04</td>\n",
       "      <td>15466.857347</td>\n",
       "      <td>0.081351</td>\n",
       "      <td>0.006668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.920840</td>\n",
       "      <td>0.847734</td>\n",
       "      <td>0.024768</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.157252</td>\n",
       "      <td>0.007675</td>\n",
       "      <td>1.362346e+05</td>\n",
       "      <td>11675.268054</td>\n",
       "      <td>0.065159</td>\n",
       "      <td>0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.920456</td>\n",
       "      <td>0.846996</td>\n",
       "      <td>0.013719</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.117126</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>1.066967e+05</td>\n",
       "      <td>20105.360464</td>\n",
       "      <td>0.075844</td>\n",
       "      <td>0.005128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.919330</td>\n",
       "      <td>0.847568</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.141703</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>1.373506e+05</td>\n",
       "      <td>10953.872552</td>\n",
       "      <td>0.106075</td>\n",
       "      <td>0.004135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.916010</td>\n",
       "      <td>0.842238</td>\n",
       "      <td>0.019962</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.141279</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>8.046139e+04</td>\n",
       "      <td>6548.076281</td>\n",
       "      <td>0.081299</td>\n",
       "      <td>0.001126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.049577</td>\n",
       "      <td>0.980151</td>\n",
       "      <td>0.027332</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.165320</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>6.328486e+04</td>\n",
       "      <td>24972.401719</td>\n",
       "      <td>0.108425</td>\n",
       "      <td>0.002218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.917170</td>\n",
       "      <td>0.844064</td>\n",
       "      <td>0.031483</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>0.177281</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>7.085241e+01</td>\n",
       "      <td>5.992206</td>\n",
       "      <td>0.105285</td>\n",
       "      <td>0.003564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.917840</td>\n",
       "      <td>0.846082</td>\n",
       "      <td>0.013314</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.115353</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>2.228576e+06</td>\n",
       "      <td>284074.086775</td>\n",
       "      <td>0.067837</td>\n",
       "      <td>0.003765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.928582</td>\n",
       "      <td>0.853519</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.122508</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>1.257358e+05</td>\n",
       "      <td>19657.483543</td>\n",
       "      <td>0.081203</td>\n",
       "      <td>0.001385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.926287</td>\n",
       "      <td>0.853516</td>\n",
       "      <td>0.012490</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.111645</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>1.361499e+05</td>\n",
       "      <td>11371.219533</td>\n",
       "      <td>0.072396</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.915899</td>\n",
       "      <td>0.844474</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.141216</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>1.221339e+05</td>\n",
       "      <td>41781.638805</td>\n",
       "      <td>0.089444</td>\n",
       "      <td>0.002158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.913718</td>\n",
       "      <td>0.842955</td>\n",
       "      <td>0.020175</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.142036</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>1.064310e+05</td>\n",
       "      <td>8542.186038</td>\n",
       "      <td>0.095496</td>\n",
       "      <td>0.004554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.912150</td>\n",
       "      <td>0.839053</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.098898</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>1.357186e+05</td>\n",
       "      <td>15147.543672</td>\n",
       "      <td>0.058785</td>\n",
       "      <td>0.000782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.928497</td>\n",
       "      <td>0.853044</td>\n",
       "      <td>0.013835</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.117620</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>9.425089e+04</td>\n",
       "      <td>9137.664011</td>\n",
       "      <td>0.071609</td>\n",
       "      <td>0.001777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.920048</td>\n",
       "      <td>0.847440</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.133541</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>2.731333e+05</td>\n",
       "      <td>53358.913538</td>\n",
       "      <td>0.089134</td>\n",
       "      <td>0.004933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.906004</td>\n",
       "      <td>0.834893</td>\n",
       "      <td>0.014832</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.121782</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>9.700089e+04</td>\n",
       "      <td>33674.541976</td>\n",
       "      <td>0.079932</td>\n",
       "      <td>0.004044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.056621</td>\n",
       "      <td>0.982581</td>\n",
       "      <td>0.013556</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.116410</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>7.317915e+04</td>\n",
       "      <td>12866.705702</td>\n",
       "      <td>0.066314</td>\n",
       "      <td>0.003393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.919682</td>\n",
       "      <td>0.847583</td>\n",
       "      <td>0.032622</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>0.180409</td>\n",
       "      <td>0.010595</td>\n",
       "      <td>3.664376e+05</td>\n",
       "      <td>98188.035939</td>\n",
       "      <td>0.139964</td>\n",
       "      <td>0.007410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.918806</td>\n",
       "      <td>0.848032</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.133017</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>1.197097e+05</td>\n",
       "      <td>24967.851237</td>\n",
       "      <td>0.099132</td>\n",
       "      <td>0.003052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.916646</td>\n",
       "      <td>0.844890</td>\n",
       "      <td>0.020570</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.143378</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>8.808099e+04</td>\n",
       "      <td>7810.265892</td>\n",
       "      <td>0.085225</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.918041</td>\n",
       "      <td>0.847152</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.099164</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>1.063615e+05</td>\n",
       "      <td>16936.881243</td>\n",
       "      <td>0.059073</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.914863</td>\n",
       "      <td>0.842117</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.089547</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>2.383172e+05</td>\n",
       "      <td>23891.521434</td>\n",
       "      <td>0.066469</td>\n",
       "      <td>0.006429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.923433</td>\n",
       "      <td>0.850979</td>\n",
       "      <td>0.020736</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.143998</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>3.566690e+04</td>\n",
       "      <td>26211.665935</td>\n",
       "      <td>0.083061</td>\n",
       "      <td>0.002180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.918187</td>\n",
       "      <td>0.847102</td>\n",
       "      <td>0.024490</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.156356</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>9.186790e+04</td>\n",
       "      <td>8834.595011</td>\n",
       "      <td>0.092825</td>\n",
       "      <td>0.004312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.924752</td>\n",
       "      <td>0.851650</td>\n",
       "      <td>0.018883</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.137394</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>1.332070e+05</td>\n",
       "      <td>2217.046637</td>\n",
       "      <td>0.097299</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.915567</td>\n",
       "      <td>0.844469</td>\n",
       "      <td>0.011290</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.106251</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>4.915062e+04</td>\n",
       "      <td>12929.084220</td>\n",
       "      <td>0.045162</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.052257</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.135387</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>3.935389e+05</td>\n",
       "      <td>81471.002063</td>\n",
       "      <td>0.099478</td>\n",
       "      <td>0.002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.914083</td>\n",
       "      <td>0.841990</td>\n",
       "      <td>0.017554</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.132475</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>2.090110e+06</td>\n",
       "      <td>400278.500862</td>\n",
       "      <td>0.087296</td>\n",
       "      <td>0.004431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    architecture  train_time  avg_time_epoch       mse   mse_std      rmse  \\\n",
       "0   Dense_L3_U16    0.940380        0.861906  0.034988  0.001341  0.187027   \n",
       "1   Dense_L3_U16    0.915245        0.844485  0.018157  0.000662  0.134733   \n",
       "2   Dense_L3_U16    0.912691        0.841930  0.019733  0.000712  0.140459   \n",
       "3   Dense_L3_U16    0.920840        0.847734  0.024768  0.002448  0.157252   \n",
       "4   Dense_L3_U16    0.920456        0.846996  0.013719  0.000217  0.117126   \n",
       "5   Dense_L3_U16    0.919330        0.847568  0.020080  0.000217  0.141703   \n",
       "6   Dense_L3_U16    0.916010        0.842238  0.019962  0.000498  0.141279   \n",
       "7   Dense_L3_U16    1.049577        0.980151  0.027332  0.000426  0.165320   \n",
       "8   Dense_L3_U16    0.917170        0.844064  0.031483  0.003176  0.177281   \n",
       "9   Dense_L3_U16    0.917840        0.846082  0.013314  0.000794  0.115353   \n",
       "10  Dense_L3_U16    0.928582        0.853519  0.015014  0.000740  0.122508   \n",
       "11  Dense_L3_U16    0.926287        0.853516  0.012490  0.001404  0.111645   \n",
       "12  Dense_L3_U16    0.915899        0.844474  0.019956  0.001282  0.141216   \n",
       "13  Dense_L3_U16    0.913718        0.842955  0.020175  0.000372  0.142036   \n",
       "14  Dense_L3_U16    0.912150        0.839053  0.009781  0.000029  0.098898   \n",
       "15  Dense_L3_U16    0.928497        0.853044  0.013835  0.000191  0.117620   \n",
       "16  Dense_L3_U16    0.920048        0.847440  0.017838  0.000745  0.133541   \n",
       "17  Dense_L3_U16    0.906004        0.834893  0.014832  0.000338  0.121782   \n",
       "18  Dense_L3_U16    1.056621        0.982581  0.013556  0.000634  0.116410   \n",
       "19  Dense_L3_U16    0.919682        0.847583  0.032622  0.003875  0.180409   \n",
       "20  Dense_L3_U16    0.918806        0.848032  0.017694  0.000108  0.133017   \n",
       "21  Dense_L3_U16    0.916646        0.844890  0.020570  0.001261  0.143378   \n",
       "22  Dense_L3_U16    0.918041        0.847152  0.009834  0.000055  0.099164   \n",
       "23  Dense_L3_U16    0.914863        0.842117  0.008026  0.000596  0.089547   \n",
       "24  Dense_L3_U16    0.923433        0.850979  0.020736  0.000253  0.143998   \n",
       "25  Dense_L3_U16    0.918187        0.847102  0.024490  0.002524  0.156356   \n",
       "26  Dense_L3_U16    0.924752        0.851650  0.018883  0.000842  0.137394   \n",
       "27  Dense_L3_U16    0.915567        0.844469  0.011290  0.000257  0.106251   \n",
       "28  Dense_L3_U16    1.052257        0.979804  0.018360  0.001815  0.135387   \n",
       "29  Dense_L3_U16    0.914083        0.841990  0.017554  0.000692  0.132475   \n",
       "\n",
       "    rmse_std          mape       mape_std       mae   mae_std  \n",
       "0   0.003599  1.253973e+05   46866.889580  0.134483  0.008541  \n",
       "1   0.002444  1.812737e+05   40845.543470  0.078444  0.002914  \n",
       "2   0.002547  6.088697e+04   15466.857347  0.081351  0.006668  \n",
       "3   0.007675  1.362346e+05   11675.268054  0.065159  0.000484  \n",
       "4   0.000926  1.066967e+05   20105.360464  0.075844  0.005128  \n",
       "5   0.000765  1.373506e+05   10953.872552  0.106075  0.004135  \n",
       "6   0.001763  8.046139e+04    6548.076281  0.081299  0.001126  \n",
       "7   0.001289  6.328486e+04   24972.401719  0.108425  0.002218  \n",
       "8   0.009056  7.085241e+01       5.992206  0.105285  0.003564  \n",
       "9   0.003414  2.228576e+06  284074.086775  0.067837  0.003765  \n",
       "10  0.003010  1.257358e+05   19657.483543  0.081203  0.001385  \n",
       "11  0.006225  1.361499e+05   11371.219533  0.072396  0.000993  \n",
       "12  0.004567  1.221339e+05   41781.638805  0.089444  0.002158  \n",
       "13  0.001310  1.064310e+05    8542.186038  0.095496  0.004554  \n",
       "14  0.000145  1.357186e+05   15147.543672  0.058785  0.000782  \n",
       "15  0.000812  9.425089e+04    9137.664011  0.071609  0.001777  \n",
       "16  0.002777  2.731333e+05   53358.913538  0.089134  0.004933  \n",
       "17  0.001388  9.700089e+04   33674.541976  0.079932  0.004044  \n",
       "18  0.002739  7.317915e+04   12866.705702  0.066314  0.003393  \n",
       "19  0.010595  3.664376e+05   98188.035939  0.139964  0.007410  \n",
       "20  0.000406  1.197097e+05   24967.851237  0.099132  0.003052  \n",
       "21  0.004389  8.808099e+04    7810.265892  0.085225  0.000898  \n",
       "22  0.000279  1.063615e+05   16936.881243  0.059073  0.001525  \n",
       "23  0.003291  2.383172e+05   23891.521434  0.066469  0.006429  \n",
       "24  0.000880  3.566690e+04   26211.665935  0.083061  0.002180  \n",
       "25  0.008029  9.186790e+04    8834.595011  0.092825  0.004312  \n",
       "26  0.003048  1.332070e+05    2217.046637  0.097299  0.000194  \n",
       "27  0.001214  4.915062e+04   12929.084220  0.045162  0.001037  \n",
       "28  0.006735  3.935389e+05   81471.002063  0.099478  0.002395  \n",
       "29  0.002602  2.090110e+06  400278.500862  0.087296  0.004431  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_csv(f'evaluations/clustered_federated_learning/{architecture}_2.csv')\n",
    "print(results[\"mse\"].mean())\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_0/BiLSTM_L2_U20/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_0/BiLSTM_L2_U20/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_1/BiLSTM_L2_U20/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_1/BiLSTM_L2_U20/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_2/BiLSTM_L2_U20/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_2/BiLSTM_L2_U20/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_3/BiLSTM_L2_U20/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_3/BiLSTM_L2_U20/FederatedRound0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Federated training round ---------- 1 / 3\n",
      "Cluster 0:\n",
      "User 1\n",
      "User 2\n",
      "User 4\n",
      "User 5\n",
      "User 7\n",
      "User 10\n",
      "User 11\n",
      "User 12\n",
      "User 15\n",
      "User 16\n",
      "User 17\n",
      "User 21\n",
      "User 22\n",
      "User 23\n",
      "User 24\n",
      "User 25\n",
      "User 28\n",
      "User 30\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_0/BiLSTM_L2_U20/FederatedRound1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_0/BiLSTM_L2_U20/FederatedRound1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Cluster 1:\n",
      "User 29\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_1/BiLSTM_L2_U20/FederatedRound1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_1/BiLSTM_L2_U20/FederatedRound1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Cluster 2:\n",
      "User 6\n",
      "User 13\n",
      "User 18\n",
      "User 20\n",
      "User 26\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_2/BiLSTM_L2_U20/FederatedRound1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_2/BiLSTM_L2_U20/FederatedRound1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Cluster 3:\n",
      "User 3\n",
      "User 8\n",
      "User 9\n",
      "User 14\n",
      "User 19\n",
      "User 27\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_3/BiLSTM_L2_U20/FederatedRound1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_3/BiLSTM_L2_U20/FederatedRound1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Started Federated training round ---------- 2 / 3\n",
      "Cluster 0:\n",
      "User 1\n",
      "User 2\n",
      "User 4\n",
      "User 5\n",
      "User 7\n",
      "User 10\n",
      "User 11\n",
      "User 12\n",
      "User 15\n",
      "User 16\n",
      "User 17\n",
      "User 21\n",
      "User 22\n",
      "User 23\n",
      "User 24\n",
      "User 25\n",
      "User 28\n",
      "User 30\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_0/BiLSTM_L2_U20/FederatedRound2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_0/BiLSTM_L2_U20/FederatedRound2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Cluster 1:\n",
      "User 29\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_1/BiLSTM_L2_U20/FederatedRound2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_1/BiLSTM_L2_U20/FederatedRound2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Cluster 2:\n",
      "User 6\n",
      "User 13\n",
      "User 18\n",
      "User 20\n",
      "User 26\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_2/BiLSTM_L2_U20/FederatedRound2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_2/BiLSTM_L2_U20/FederatedRound2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Cluster 3:\n",
      "User 3\n",
      "User 8\n",
      "User 9\n",
      "User 14\n",
      "User 19\n",
      "User 27\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_3/BiLSTM_L2_U20/FederatedRound2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_3/BiLSTM_L2_U20/FederatedRound2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Started Federated training round ---------- 3 / 3\n",
      "Cluster 0:\n",
      "User 1\n",
      "User 2\n",
      "User 4\n",
      "User 5\n",
      "User 7\n",
      "User 10\n",
      "User 11\n",
      "User 12\n",
      "User 15\n",
      "User 16\n",
      "User 17\n",
      "User 21\n",
      "User 22\n",
      "User 23\n",
      "User 24\n",
      "User 25\n",
      "User 28\n",
      "User 30\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_0/BiLSTM_L2_U20/FederatedRound3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_0/BiLSTM_L2_U20/FederatedRound3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Cluster 1:\n",
      "User 29\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_1/BiLSTM_L2_U20/FederatedRound3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_1/BiLSTM_L2_U20/FederatedRound3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Cluster 2:\n",
      "User 6\n",
      "User 13\n",
      "User 18\n",
      "User 20\n",
      "User 26\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_2/BiLSTM_L2_U20/FederatedRound3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_2/BiLSTM_L2_U20/FederatedRound3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Cluster 3:\n",
      "User 3\n",
      "User 8\n",
      "User 9\n",
      "User 14\n",
      "User 19\n",
      "User 27\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_3/BiLSTM_L2_U20/FederatedRound3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\rs1044\\bwSyncShare\\02Python Code\\MoE-based-FL-for-secure-STLF/models/FL/Dense/global_dense_model/cluster_3/BiLSTM_L2_U20/FederatedRound3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Global models\n",
      "Cluster 0:\n",
      "User:  1\n",
      "User:  2\n",
      "User:  4\n",
      "User:  5\n",
      "User:  7\n",
      "User:  10\n",
      "User:  11\n",
      "User:  12\n",
      "User:  15\n",
      "User:  16\n",
      "User:  17\n",
      "User:  21\n",
      "User:  22\n",
      "User:  23\n",
      "User:  24\n",
      "User:  25\n",
      "User:  28\n",
      "User:  30\n",
      "Cluster 1:\n",
      "User:  29\n",
      "Cluster 2:\n",
      "User:  6\n",
      "User:  13\n",
      "User:  18\n",
      "User:  20\n",
      "User:  26\n",
      "Cluster 3:\n",
      "User:  3\n",
      "User:  8\n",
      "User:  9\n",
      "User:  14\n",
      "User:  19\n",
      "User:  27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architecture</th>\n",
       "      <th>train_time</th>\n",
       "      <th>avg_time_epoch</th>\n",
       "      <th>mse</th>\n",
       "      <th>mse_std</th>\n",
       "      <th>rmse</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>mape</th>\n",
       "      <th>mape_std</th>\n",
       "      <th>mae</th>\n",
       "      <th>mae_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.935475</td>\n",
       "      <td>0.859926</td>\n",
       "      <td>0.034367</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.185379</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>8.435151e+04</td>\n",
       "      <td>5276.563581</td>\n",
       "      <td>0.134481</td>\n",
       "      <td>0.001163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.062256</td>\n",
       "      <td>0.988570</td>\n",
       "      <td>0.016742</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.129387</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>2.894397e+05</td>\n",
       "      <td>17633.278160</td>\n",
       "      <td>0.076471</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.926651</td>\n",
       "      <td>0.854965</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.137447</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>4.547944e+04</td>\n",
       "      <td>6384.431282</td>\n",
       "      <td>0.076337</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.923367</td>\n",
       "      <td>0.851295</td>\n",
       "      <td>0.022242</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.149128</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>1.328210e+05</td>\n",
       "      <td>7263.428431</td>\n",
       "      <td>0.063521</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.921280</td>\n",
       "      <td>0.849261</td>\n",
       "      <td>0.013165</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.114735</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>8.575916e+04</td>\n",
       "      <td>7781.146682</td>\n",
       "      <td>0.073596</td>\n",
       "      <td>0.001301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.922215</td>\n",
       "      <td>0.848528</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.138637</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>1.000368e+05</td>\n",
       "      <td>8598.919788</td>\n",
       "      <td>0.100257</td>\n",
       "      <td>0.002861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.933126</td>\n",
       "      <td>0.859773</td>\n",
       "      <td>0.018804</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.137116</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>7.152170e+04</td>\n",
       "      <td>6090.935211</td>\n",
       "      <td>0.081467</td>\n",
       "      <td>0.001777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.944919</td>\n",
       "      <td>0.869899</td>\n",
       "      <td>0.023224</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.152384</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>1.423177e+04</td>\n",
       "      <td>6381.654232</td>\n",
       "      <td>0.098019</td>\n",
       "      <td>0.000635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.924121</td>\n",
       "      <td>0.850769</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>6.658551e+01</td>\n",
       "      <td>8.269819</td>\n",
       "      <td>0.090012</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.082936</td>\n",
       "      <td>1.008213</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.113077</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>2.638208e+06</td>\n",
       "      <td>370528.215327</td>\n",
       "      <td>0.069678</td>\n",
       "      <td>0.004041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.929922</td>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.120801</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>9.364932e+04</td>\n",
       "      <td>13583.632441</td>\n",
       "      <td>0.078773</td>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.955976</td>\n",
       "      <td>0.881290</td>\n",
       "      <td>0.009364</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.096769</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>1.150177e+05</td>\n",
       "      <td>5418.352843</td>\n",
       "      <td>0.065870</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.862940</td>\n",
       "      <td>0.017601</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.132648</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>1.269672e+05</td>\n",
       "      <td>20737.326466</td>\n",
       "      <td>0.086731</td>\n",
       "      <td>0.001703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.922245</td>\n",
       "      <td>0.849893</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.139748</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>7.681692e+04</td>\n",
       "      <td>845.380460</td>\n",
       "      <td>0.092276</td>\n",
       "      <td>0.004179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.097445</td>\n",
       "      <td>1.023092</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.097945</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>1.255156e+05</td>\n",
       "      <td>4264.534923</td>\n",
       "      <td>0.057032</td>\n",
       "      <td>0.001594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.929354</td>\n",
       "      <td>0.856337</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.115034</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>7.891706e+04</td>\n",
       "      <td>13231.180554</td>\n",
       "      <td>0.073675</td>\n",
       "      <td>0.005404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.914196</td>\n",
       "      <td>0.842844</td>\n",
       "      <td>0.016357</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.127894</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>1.924626e+05</td>\n",
       "      <td>19453.339047</td>\n",
       "      <td>0.082780</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.065188</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.120002</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>1.099799e+05</td>\n",
       "      <td>14309.240664</td>\n",
       "      <td>0.078957</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.932972</td>\n",
       "      <td>0.858954</td>\n",
       "      <td>0.012446</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.111559</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>7.627168e+04</td>\n",
       "      <td>11818.958875</td>\n",
       "      <td>0.064049</td>\n",
       "      <td>0.002994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.924359</td>\n",
       "      <td>0.851007</td>\n",
       "      <td>0.027298</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.165212</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>3.126191e+05</td>\n",
       "      <td>13758.746803</td>\n",
       "      <td>0.125150</td>\n",
       "      <td>0.001880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.058920</td>\n",
       "      <td>0.986234</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.131013</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>1.093631e+05</td>\n",
       "      <td>9383.379934</td>\n",
       "      <td>0.094754</td>\n",
       "      <td>0.000586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.927943</td>\n",
       "      <td>0.855925</td>\n",
       "      <td>0.019867</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.140949</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>6.890213e+04</td>\n",
       "      <td>17338.209426</td>\n",
       "      <td>0.084138</td>\n",
       "      <td>0.004433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.921413</td>\n",
       "      <td>0.849393</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.098696</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>1.523651e+05</td>\n",
       "      <td>6607.779982</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.002688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.925600</td>\n",
       "      <td>0.852914</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>2.524177e+05</td>\n",
       "      <td>13017.094582</td>\n",
       "      <td>0.067936</td>\n",
       "      <td>0.003585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.068567</td>\n",
       "      <td>0.997215</td>\n",
       "      <td>0.019176</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>5.345651e+04</td>\n",
       "      <td>8628.735823</td>\n",
       "      <td>0.083180</td>\n",
       "      <td>0.004681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.939136</td>\n",
       "      <td>0.867451</td>\n",
       "      <td>0.023222</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.152338</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>9.962139e+04</td>\n",
       "      <td>14185.005680</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.003352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.917892</td>\n",
       "      <td>0.846874</td>\n",
       "      <td>0.017549</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.132466</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>1.984469e+05</td>\n",
       "      <td>14590.364906</td>\n",
       "      <td>0.091239</td>\n",
       "      <td>0.002184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.934186</td>\n",
       "      <td>0.861500</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.102452</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>5.662376e+04</td>\n",
       "      <td>3990.076807</td>\n",
       "      <td>0.044518</td>\n",
       "      <td>0.002084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.931012</td>\n",
       "      <td>0.858222</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.130813</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>4.972088e+05</td>\n",
       "      <td>32368.690097</td>\n",
       "      <td>0.095624</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.923778</td>\n",
       "      <td>0.851092</td>\n",
       "      <td>0.016269</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.127549</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>1.682560e+06</td>\n",
       "      <td>218047.603417</td>\n",
       "      <td>0.080090</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>8.043848</td>\n",
       "      <td>7.822312</td>\n",
       "      <td>0.034842</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.186661</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>1.199604e+05</td>\n",
       "      <td>10003.129930</td>\n",
       "      <td>0.130790</td>\n",
       "      <td>0.001550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>8.553803</td>\n",
       "      <td>8.302577</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.135926</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>2.891908e+05</td>\n",
       "      <td>30156.320588</td>\n",
       "      <td>0.084132</td>\n",
       "      <td>0.003165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.596096</td>\n",
       "      <td>9.305025</td>\n",
       "      <td>0.020946</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.144726</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>6.538525e+04</td>\n",
       "      <td>6783.608442</td>\n",
       "      <td>0.077482</td>\n",
       "      <td>0.002826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.585961</td>\n",
       "      <td>9.309225</td>\n",
       "      <td>0.023611</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.153637</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>1.120320e+05</td>\n",
       "      <td>4562.167521</td>\n",
       "      <td>0.065986</td>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.821063</td>\n",
       "      <td>9.522313</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.121598</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>8.399784e+04</td>\n",
       "      <td>5949.039975</td>\n",
       "      <td>0.078531</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.433237</td>\n",
       "      <td>10.108335</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.144988</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>9.284055e+04</td>\n",
       "      <td>5132.222849</td>\n",
       "      <td>0.101388</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.604595</td>\n",
       "      <td>9.314773</td>\n",
       "      <td>0.020866</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.144447</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>8.890880e+04</td>\n",
       "      <td>11019.849717</td>\n",
       "      <td>0.082394</td>\n",
       "      <td>0.002419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.862503</td>\n",
       "      <td>9.558763</td>\n",
       "      <td>0.031534</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.177457</td>\n",
       "      <td>0.008053</td>\n",
       "      <td>3.459638e+04</td>\n",
       "      <td>6117.639717</td>\n",
       "      <td>0.113371</td>\n",
       "      <td>0.006483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.802432</td>\n",
       "      <td>9.513968</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.182785</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>9.198628e+01</td>\n",
       "      <td>12.169439</td>\n",
       "      <td>0.114112</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.547521</td>\n",
       "      <td>9.270302</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.119418</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>1.686744e+06</td>\n",
       "      <td>208187.657257</td>\n",
       "      <td>0.067947</td>\n",
       "      <td>0.002306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.490013</td>\n",
       "      <td>9.201434</td>\n",
       "      <td>0.015883</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.126009</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>1.014370e+05</td>\n",
       "      <td>33329.395126</td>\n",
       "      <td>0.081669</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.645222</td>\n",
       "      <td>9.370821</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.107443</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>1.020909e+05</td>\n",
       "      <td>4686.943492</td>\n",
       "      <td>0.065361</td>\n",
       "      <td>0.004560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.268017</td>\n",
       "      <td>9.949940</td>\n",
       "      <td>0.019108</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.138218</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>1.037386e+05</td>\n",
       "      <td>19787.977372</td>\n",
       "      <td>0.086417</td>\n",
       "      <td>0.002797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.173183</td>\n",
       "      <td>9.860774</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.141505</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>8.869359e+04</td>\n",
       "      <td>5977.486383</td>\n",
       "      <td>0.090766</td>\n",
       "      <td>0.002192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.088636</td>\n",
       "      <td>8.816166</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.098334</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>1.078278e+05</td>\n",
       "      <td>15401.820937</td>\n",
       "      <td>0.053588</td>\n",
       "      <td>0.002392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.269321</td>\n",
       "      <td>9.002590</td>\n",
       "      <td>0.015441</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.124256</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>9.314463e+04</td>\n",
       "      <td>15808.288012</td>\n",
       "      <td>0.078160</td>\n",
       "      <td>0.004771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.312286</td>\n",
       "      <td>9.994206</td>\n",
       "      <td>0.017808</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.133440</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>3.453294e+05</td>\n",
       "      <td>5263.339768</td>\n",
       "      <td>0.085826</td>\n",
       "      <td>0.002607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.103730</td>\n",
       "      <td>9.806659</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.122064</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>1.089739e+05</td>\n",
       "      <td>5105.820718</td>\n",
       "      <td>0.079586</td>\n",
       "      <td>0.002962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.858960</td>\n",
       "      <td>9.568348</td>\n",
       "      <td>0.013053</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.114245</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>1.207443e+05</td>\n",
       "      <td>11786.179928</td>\n",
       "      <td>0.069274</td>\n",
       "      <td>0.002799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.755573</td>\n",
       "      <td>9.456821</td>\n",
       "      <td>0.032501</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.180116</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>2.304622e+05</td>\n",
       "      <td>24636.004251</td>\n",
       "      <td>0.137657</td>\n",
       "      <td>0.008010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.019087</td>\n",
       "      <td>9.726683</td>\n",
       "      <td>0.018534</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.136135</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>1.305718e+05</td>\n",
       "      <td>10607.219976</td>\n",
       "      <td>0.099479</td>\n",
       "      <td>0.001784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.305491</td>\n",
       "      <td>9.985619</td>\n",
       "      <td>0.022903</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.151328</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>5.410743e+04</td>\n",
       "      <td>19088.628763</td>\n",
       "      <td>0.086244</td>\n",
       "      <td>0.007827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.200289</td>\n",
       "      <td>9.902166</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.101621</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>1.262740e+05</td>\n",
       "      <td>15922.253807</td>\n",
       "      <td>0.066076</td>\n",
       "      <td>0.003399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.035945</td>\n",
       "      <td>9.729447</td>\n",
       "      <td>0.008408</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.091691</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>1.903960e+05</td>\n",
       "      <td>25674.702242</td>\n",
       "      <td>0.064891</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.228079</td>\n",
       "      <td>9.926963</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.145920</td>\n",
       "      <td>0.007720</td>\n",
       "      <td>2.807344e+04</td>\n",
       "      <td>17603.283487</td>\n",
       "      <td>0.087852</td>\n",
       "      <td>0.011733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.495786</td>\n",
       "      <td>9.219285</td>\n",
       "      <td>0.028025</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.167394</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>1.236301e+05</td>\n",
       "      <td>6610.568969</td>\n",
       "      <td>0.101930</td>\n",
       "      <td>0.003398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.283620</td>\n",
       "      <td>9.971138</td>\n",
       "      <td>0.021571</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.146862</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>1.042787e+05</td>\n",
       "      <td>10722.828420</td>\n",
       "      <td>0.106130</td>\n",
       "      <td>0.001971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.854997</td>\n",
       "      <td>9.555230</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.103476</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>4.903854e+04</td>\n",
       "      <td>8342.004516</td>\n",
       "      <td>0.044523</td>\n",
       "      <td>0.002417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.170537</td>\n",
       "      <td>9.875401</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.147772</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>3.988970e+05</td>\n",
       "      <td>91112.174742</td>\n",
       "      <td>0.100551</td>\n",
       "      <td>0.004605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.254177</td>\n",
       "      <td>9.949657</td>\n",
       "      <td>0.018260</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.135124</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>1.957792e+06</td>\n",
       "      <td>257737.276454</td>\n",
       "      <td>0.087721</td>\n",
       "      <td>0.002741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     architecture  train_time  avg_time_epoch       mse   mse_std      rmse  \\\n",
       "0    Dense_L3_U16    0.935475        0.859926  0.034367  0.000558  0.185379   \n",
       "1    Dense_L3_U16    1.062256        0.988570  0.016742  0.000258  0.129387   \n",
       "2    Dense_L3_U16    0.926651        0.854965  0.018892  0.000258  0.137447   \n",
       "3    Dense_L3_U16    0.923367        0.851295  0.022242  0.000605  0.149128   \n",
       "4    Dense_L3_U16    0.921280        0.849261  0.013165  0.000217  0.114735   \n",
       "5    Dense_L3_U16    0.922215        0.848528  0.019220  0.000138  0.138637   \n",
       "6    Dense_L3_U16    0.933126        0.859773  0.018804  0.000615  0.137116   \n",
       "7    Dense_L3_U16    0.944919        0.869899  0.023224  0.000673  0.152384   \n",
       "8    Dense_L3_U16    0.924121        0.850769  0.024089  0.001217  0.155172   \n",
       "9    Dense_L3_U16    1.082936        1.008213  0.012787  0.000257  0.113077   \n",
       "10   Dense_L3_U16    0.929922        0.855903  0.014594  0.000291  0.120801   \n",
       "11   Dense_L3_U16    0.955976        0.881290  0.009364  0.000030  0.096769   \n",
       "12   Dense_L3_U16    0.934959        0.862940  0.017601  0.000795  0.132648   \n",
       "13   Dense_L3_U16    0.922245        0.849893  0.019530  0.000174  0.139748   \n",
       "14   Dense_L3_U16    1.097445        1.023092  0.009593  0.000056  0.097945   \n",
       "15   Dense_L3_U16    0.929354        0.856337  0.013233  0.000141  0.115034   \n",
       "16   Dense_L3_U16    0.914196        0.842844  0.016357  0.000212  0.127894   \n",
       "17   Dense_L3_U16    1.065188        0.991836  0.014401  0.000088  0.120002   \n",
       "18   Dense_L3_U16    0.932972        0.858954  0.012446  0.000236  0.111559   \n",
       "19   Dense_L3_U16    0.924359        0.851007  0.027298  0.000721  0.165212   \n",
       "20   Dense_L3_U16    1.058920        0.986234  0.017166  0.000427  0.131013   \n",
       "21   Dense_L3_U16    0.927943        0.855925  0.019867  0.000108  0.140949   \n",
       "22   Dense_L3_U16    0.921413        0.849393  0.009741  0.000092  0.098696   \n",
       "23   Dense_L3_U16    0.925600        0.852914  0.007952  0.000413  0.089154   \n",
       "24   Dense_L3_U16    1.068567        0.997215  0.019176  0.000668  0.138462   \n",
       "25   Dense_L3_U16    0.939136        0.867451  0.023222  0.001491  0.152338   \n",
       "26   Dense_L3_U16    0.917892        0.846874  0.017549  0.000380  0.132466   \n",
       "27   Dense_L3_U16    0.934186        0.861500  0.010497  0.000230  0.102452   \n",
       "28   Dense_L3_U16    0.931012        0.858222  0.017116  0.000587  0.130813   \n",
       "29   Dense_L3_U16    0.923778        0.851092  0.016269  0.000142  0.127549   \n",
       "30  BiLSTM_L2_U20    8.043848        7.822312  0.034842  0.000171  0.186661   \n",
       "31  BiLSTM_L2_U20    8.553803        8.302577  0.018476  0.000147  0.135926   \n",
       "32  BiLSTM_L2_U20    9.596096        9.305025  0.020946  0.000203  0.144726   \n",
       "33  BiLSTM_L2_U20    9.585961        9.309225  0.023611  0.000952  0.153637   \n",
       "34  BiLSTM_L2_U20    9.821063        9.522313  0.014790  0.000569  0.121598   \n",
       "35  BiLSTM_L2_U20   10.433237       10.108335  0.021022  0.000217  0.144988   \n",
       "36  BiLSTM_L2_U20    9.604595        9.314773  0.020866  0.000316  0.144447   \n",
       "37  BiLSTM_L2_U20    9.862503        9.558763  0.031534  0.002854  0.177457   \n",
       "38  BiLSTM_L2_U20    9.802432        9.513968  0.033448  0.002757  0.182785   \n",
       "39  BiLSTM_L2_U20    9.547521        9.270302  0.014262  0.000319  0.119418   \n",
       "40  BiLSTM_L2_U20    9.490013        9.201434  0.015883  0.000681  0.126009   \n",
       "41  BiLSTM_L2_U20    9.645222        9.370821  0.011565  0.001211  0.107443   \n",
       "42  BiLSTM_L2_U20   10.268017        9.949940  0.019108  0.000619  0.138218   \n",
       "43  BiLSTM_L2_U20   10.173183        9.860774  0.020024  0.000322  0.141505   \n",
       "44  BiLSTM_L2_U20    9.088636        8.816166  0.009670  0.000136  0.098334   \n",
       "45  BiLSTM_L2_U20    9.269321        9.002590  0.015441  0.000406  0.124256   \n",
       "46  BiLSTM_L2_U20   10.312286        9.994206  0.017808  0.000486  0.133440   \n",
       "47  BiLSTM_L2_U20   10.103730        9.806659  0.014900  0.000097  0.122064   \n",
       "48  BiLSTM_L2_U20    9.858960        9.568348  0.013053  0.000247  0.114245   \n",
       "49  BiLSTM_L2_U20    9.755573        9.456821  0.032501  0.003369  0.180116   \n",
       "50  BiLSTM_L2_U20   10.019087        9.726683  0.018534  0.000402  0.136135   \n",
       "51  BiLSTM_L2_U20   10.305491        9.985619  0.022903  0.000573  0.151328   \n",
       "52  BiLSTM_L2_U20   10.200289        9.902166  0.010328  0.000300  0.101621   \n",
       "53  BiLSTM_L2_U20   10.035945        9.729447  0.008408  0.000125  0.091691   \n",
       "54  BiLSTM_L2_U20   10.228079        9.926963  0.021332  0.002287  0.145920   \n",
       "55  BiLSTM_L2_U20    9.495786        9.219285  0.028025  0.000885  0.167394   \n",
       "56  BiLSTM_L2_U20   10.283620        9.971138  0.021571  0.000536  0.146862   \n",
       "57  BiLSTM_L2_U20    9.854997        9.555230  0.010709  0.000384  0.103476   \n",
       "58  BiLSTM_L2_U20   10.170537        9.875401  0.021841  0.000730  0.147772   \n",
       "59  BiLSTM_L2_U20   10.254177        9.949657  0.018260  0.000427  0.135124   \n",
       "\n",
       "    rmse_std          mape       mape_std       mae   mae_std  \n",
       "0   0.001503  8.435151e+04    5276.563581  0.134481  0.001163  \n",
       "1   0.000998  2.894397e+05   17633.278160  0.076471  0.001340  \n",
       "2   0.000939  4.547944e+04    6384.431282  0.076337  0.000670  \n",
       "3   0.002022  1.328210e+05    7263.428431  0.063521  0.000920  \n",
       "4   0.000947  8.575916e+04    7781.146682  0.073596  0.001301  \n",
       "5   0.000497  1.000368e+05    8598.919788  0.100257  0.002861  \n",
       "6   0.002232  7.152170e+04    6090.935211  0.081467  0.001777  \n",
       "7   0.002216  1.423177e+04    6381.654232  0.098019  0.000635  \n",
       "8   0.003905  6.658551e+01       8.269819  0.090012  0.001159  \n",
       "9   0.001139  2.638208e+06  370528.215327  0.069678  0.004041  \n",
       "10  0.001202  9.364932e+04   13583.632441  0.078773  0.001619  \n",
       "11  0.000153  1.150177e+05    5418.352843  0.065870  0.001539  \n",
       "12  0.002977  1.269672e+05   20737.326466  0.086731  0.001703  \n",
       "13  0.000622  7.681692e+04     845.380460  0.092276  0.004179  \n",
       "14  0.000287  1.255156e+05    4264.534923  0.057032  0.001594  \n",
       "15  0.000611  7.891706e+04   13231.180554  0.073675  0.005404  \n",
       "16  0.000827  1.924626e+05   19453.339047  0.082780  0.002167  \n",
       "17  0.000367  1.099799e+05   14309.240664  0.078957  0.002105  \n",
       "18  0.001054  7.627168e+04   11818.958875  0.064049  0.002994  \n",
       "19  0.002182  3.126191e+05   13758.746803  0.125150  0.001880  \n",
       "20  0.001622  1.093631e+05    9383.379934  0.094754  0.000586  \n",
       "21  0.000385  6.890213e+04   17338.209426  0.084138  0.004433  \n",
       "22  0.000467  1.523651e+05    6607.779982  0.061127  0.002688  \n",
       "23  0.002297  2.524177e+05   13017.094582  0.067936  0.003585  \n",
       "24  0.002405  5.345651e+04    8628.735823  0.083180  0.004681  \n",
       "25  0.004852  9.962139e+04   14185.005680  0.091196  0.003352  \n",
       "26  0.001440  1.984469e+05   14590.364906  0.091239  0.002184  \n",
       "27  0.001127  5.662376e+04    3990.076807  0.044518  0.002084  \n",
       "28  0.002250  4.972088e+05   32368.690097  0.095624  0.001779  \n",
       "29  0.000556  1.682560e+06  218047.603417  0.080090  0.000898  \n",
       "30  0.000458  1.199604e+05   10003.129930  0.130790  0.001550  \n",
       "31  0.000542  2.891908e+05   30156.320588  0.084132  0.003165  \n",
       "32  0.000701  6.538525e+04    6783.608442  0.077482  0.002826  \n",
       "33  0.003082  1.120320e+05    4562.167521  0.065986  0.002400  \n",
       "34  0.002353  8.399784e+04    5949.039975  0.078531  0.002284  \n",
       "35  0.000750  9.284055e+04    5132.222849  0.101388  0.000544  \n",
       "36  0.001093  8.890880e+04   11019.849717  0.082394  0.002419  \n",
       "37  0.008053  3.459638e+04    6117.639717  0.113371  0.006483  \n",
       "38  0.007485  9.198628e+01      12.169439  0.114112  0.007082  \n",
       "39  0.001335  1.686744e+06  208187.657257  0.067947  0.002306  \n",
       "40  0.002688  1.014370e+05   33329.395126  0.081669  0.003333  \n",
       "41  0.005566  1.020909e+05    4686.943492  0.065361  0.004560  \n",
       "42  0.002248  1.037386e+05   19787.977372  0.086417  0.002797  \n",
       "43  0.001137  8.869359e+04    5977.486383  0.090766  0.002192  \n",
       "44  0.000693  1.078278e+05   15401.820937  0.053588  0.002392  \n",
       "45  0.001628  9.314463e+04   15808.288012  0.078160  0.004771  \n",
       "46  0.001827  3.453294e+05    5263.339768  0.085826  0.002607  \n",
       "47  0.000396  1.089739e+05    5105.820718  0.079586  0.002962  \n",
       "48  0.001079  1.207443e+05   11786.179928  0.069274  0.002799  \n",
       "49  0.009430  2.304622e+05   24636.004251  0.137657  0.008010  \n",
       "50  0.001478  1.305718e+05   10607.219976  0.099479  0.001784  \n",
       "51  0.001885  5.410743e+04   19088.628763  0.086244  0.007827  \n",
       "52  0.001478  1.262740e+05   15922.253807  0.066076  0.003399  \n",
       "53  0.000683  1.903960e+05   25674.702242  0.064891  0.001800  \n",
       "54  0.007720  2.807344e+04   17603.283487  0.087852  0.011733  \n",
       "55  0.002632  1.236301e+05    6610.568969  0.101930  0.003398  \n",
       "56  0.001826  1.042787e+05   10722.828420  0.106130  0.001971  \n",
       "57  0.001848  4.903854e+04    8342.004516  0.044523  0.002417  \n",
       "58  0.002459  3.988970e+05   91112.174742  0.100551  0.004605  \n",
       "59  0.001586  1.957792e+06  257737.276454  0.087721  0.002741  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture = \"BiLSTM_L1_U8\"\n",
    "\n",
    "lstm_layers = 1\n",
    "lstm_units = 8\n",
    "\n",
    "# Create global models for each cluser (6)\n",
    "for cluster in range(num_clusters):\n",
    "#Build and save global model\n",
    "    global_model = m1.build_bilstm_model(X_train[f'user{1}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "    global_model.save(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster}/{architecture}/FederatedRound{0}\")\n",
    "\n",
    "  \n",
    "federated_rounds = 3\n",
    "for federated_round  in range(federated_rounds):\n",
    "    print(\"Started Federated training round ----------\", federated_round+1, f\"/ {federated_rounds}\")\n",
    "\n",
    "    for cluster_number, users_in_cluster in cluster_users.items():\n",
    "        print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "        #Get global models weights\n",
    "        global_model = keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{architecture}/FederatedRound{federated_round}\", compile=False)\n",
    "        global_model_weights = global_model.get_weights()\n",
    "\n",
    "        #initial list for local model weights\n",
    "        local_model_weight_list = list()\n",
    "\n",
    "\n",
    "        #for idx, user in enumerate(df_array): \n",
    "        for user_index in users_in_cluster:\n",
    "            user_df = df_array[user_index-1]  # Get the user's DataFrame from the array\n",
    "            print(f\"User {user_index}\") \n",
    "                      \n",
    "            #build and compile local model X_train, batch_size, horizon, dense_units,  expert_units, num_experts, m1\n",
    "            local_model = m1.build_bilstm_model(X_train[f'user{user_index}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "            local_model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(learning_rate=0.0006), metrics=metrics)\n",
    "\n",
    "            #set local model weight to the weight of the global model\n",
    "            local_model.set_weights(global_model_weights)\n",
    "            \n",
    "            #Fit local model to local data\n",
    "            histroy, user_results = mh.compile_fit_evaluate_model(\n",
    "                model=local_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = max_epochs, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0006),\n",
    "            )\n",
    "            #add model weights to list        \n",
    "            local_model_weights = local_model.get_weights()\n",
    "            local_model_weight_list.append(local_model_weights)\n",
    "        \n",
    "            #clear session to free memory after each communication round\n",
    "            K.clear_session()\n",
    "        \n",
    "        #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "        average_weights = avg_weights_with_noise_fedprox(local_model_weight_list)\n",
    "        #update global model \n",
    "        global_model.set_weights(average_weights)\n",
    "        #Save global models\n",
    "        global_model.save(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{architecture}/FederatedRound{federated_round+1}\")\n",
    "        print(\"Saved Global models\")\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "all_results = pd.DataFrame(columns=[\"user\", \"architecture\", \"train_time\", \"avg_time_epoch\", \"mse\", \"rmse\", \"mape\", \"mae\"])\n",
    "\n",
    "for cluster_number, users_in_cluster in cluster_users.items():\n",
    "    print(f\"Cluster {cluster_number}:\")\n",
    "\n",
    "    #Get global models weights\n",
    "    global_model = tf.keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "\n",
    "    #for idx, user in enumerate(df_array): \n",
    "    for user_index in users_in_cluster:\n",
    "        print(\"User: \", user_index)\n",
    "        for round in range(3):\n",
    "            global_model = tf.keras.models.load_model(cwd + f\"/models/FL/Dense/global_dense_model/cluster_{cluster_number}/{architecture}/FederatedRound{federated_rounds}\", compile=False)\n",
    "            local_model = m1.build_bilstm_model(X_train[f'user{user_index}'], horizon, num_layers=lstm_layers, units=lstm_units, batch_size=batch_size)\n",
    "            local_model.set_weights(global_model.get_weights())\n",
    "            \n",
    "            histroy, user_results = mh.compile_fit_evaluate_model(\n",
    "                model=local_model, \n",
    "                loss=loss, \n",
    "                metrics=metrics, \n",
    "                X_train=X_train[f'user{user_index}'],\n",
    "                y_train = y_train[f'user{user_index}'], \n",
    "                max_epochs = 1, \n",
    "                batch_size=batch_size, \n",
    "                X_val=X_val[f'user{user_index}'], \n",
    "                y_val=y_val[f'user{user_index}'], \n",
    "                X_test=X_test[f'user{user_index}'], \n",
    "                y_test=y_test[f'user{user_index}'], \n",
    "                callbacks=callbacks, \n",
    "                user=f'user{user_index}', \n",
    "                hyper=architecture,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0006)\n",
    "            )\n",
    "            # Add the 'architecture' column from dense_user_results to dense_results\n",
    "            all_results = pd.merge(all_results, user_results, how='outer')  \n",
    "\n",
    "for idx in range(len(df_array)):\n",
    "    new_row = {\n",
    "        'architecture': architecture,\n",
    "        'train_time': all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"train_time\"].mean(), \n",
    "        'avg_time_epoch' : all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"avg_time_epoch\"].mean(),\n",
    "        'mse': all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].mean(),\n",
    "        'mse_std' : all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mse\"].std(),\n",
    "        'rmse': all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].mean(),\n",
    "        'rmse_std' : all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"rmse\"].std(),\n",
    "        'mape': all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].mean(),\n",
    "        'mape_std' : all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mape\"].std(),\n",
    "        'mae': all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].mean(),\n",
    "        'mae_std' : all_results[all_results[\"user\"]==f\"user{idx+1}\"][\"mae\"].std(),\n",
    "    }\n",
    "    results.loc[len(results)] = new_row\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architecture</th>\n",
       "      <th>train_time</th>\n",
       "      <th>avg_time_epoch</th>\n",
       "      <th>mse</th>\n",
       "      <th>mse_std</th>\n",
       "      <th>rmse</th>\n",
       "      <th>rmse_std</th>\n",
       "      <th>mape</th>\n",
       "      <th>mape_std</th>\n",
       "      <th>mae</th>\n",
       "      <th>mae_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.935475</td>\n",
       "      <td>0.859926</td>\n",
       "      <td>0.034367</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.185379</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>8.435151e+04</td>\n",
       "      <td>5276.563581</td>\n",
       "      <td>0.134481</td>\n",
       "      <td>0.001163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.062256</td>\n",
       "      <td>0.988570</td>\n",
       "      <td>0.016742</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.129387</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>2.894397e+05</td>\n",
       "      <td>17633.278160</td>\n",
       "      <td>0.076471</td>\n",
       "      <td>0.001340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.926651</td>\n",
       "      <td>0.854965</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.137447</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>4.547944e+04</td>\n",
       "      <td>6384.431282</td>\n",
       "      <td>0.076337</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.923367</td>\n",
       "      <td>0.851295</td>\n",
       "      <td>0.022242</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.149128</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>1.328210e+05</td>\n",
       "      <td>7263.428431</td>\n",
       "      <td>0.063521</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.921280</td>\n",
       "      <td>0.849261</td>\n",
       "      <td>0.013165</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.114735</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>8.575916e+04</td>\n",
       "      <td>7781.146682</td>\n",
       "      <td>0.073596</td>\n",
       "      <td>0.001301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.922215</td>\n",
       "      <td>0.848528</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.138637</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>1.000368e+05</td>\n",
       "      <td>8598.919788</td>\n",
       "      <td>0.100257</td>\n",
       "      <td>0.002861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.933126</td>\n",
       "      <td>0.859773</td>\n",
       "      <td>0.018804</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.137116</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>7.152170e+04</td>\n",
       "      <td>6090.935211</td>\n",
       "      <td>0.081467</td>\n",
       "      <td>0.001777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.944919</td>\n",
       "      <td>0.869899</td>\n",
       "      <td>0.023224</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.152384</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>1.423177e+04</td>\n",
       "      <td>6381.654232</td>\n",
       "      <td>0.098019</td>\n",
       "      <td>0.000635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.924121</td>\n",
       "      <td>0.850769</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>6.658551e+01</td>\n",
       "      <td>8.269819</td>\n",
       "      <td>0.090012</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.082936</td>\n",
       "      <td>1.008213</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.113077</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>2.638208e+06</td>\n",
       "      <td>370528.215327</td>\n",
       "      <td>0.069678</td>\n",
       "      <td>0.004041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.929922</td>\n",
       "      <td>0.855903</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.120801</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>9.364932e+04</td>\n",
       "      <td>13583.632441</td>\n",
       "      <td>0.078773</td>\n",
       "      <td>0.001619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.955976</td>\n",
       "      <td>0.881290</td>\n",
       "      <td>0.009364</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.096769</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>1.150177e+05</td>\n",
       "      <td>5418.352843</td>\n",
       "      <td>0.065870</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.862940</td>\n",
       "      <td>0.017601</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.132648</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>1.269672e+05</td>\n",
       "      <td>20737.326466</td>\n",
       "      <td>0.086731</td>\n",
       "      <td>0.001703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.922245</td>\n",
       "      <td>0.849893</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.139748</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>7.681692e+04</td>\n",
       "      <td>845.380460</td>\n",
       "      <td>0.092276</td>\n",
       "      <td>0.004179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.097445</td>\n",
       "      <td>1.023092</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.097945</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>1.255156e+05</td>\n",
       "      <td>4264.534923</td>\n",
       "      <td>0.057032</td>\n",
       "      <td>0.001594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.929354</td>\n",
       "      <td>0.856337</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.115034</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>7.891706e+04</td>\n",
       "      <td>13231.180554</td>\n",
       "      <td>0.073675</td>\n",
       "      <td>0.005404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.914196</td>\n",
       "      <td>0.842844</td>\n",
       "      <td>0.016357</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.127894</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>1.924626e+05</td>\n",
       "      <td>19453.339047</td>\n",
       "      <td>0.082780</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.065188</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.120002</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>1.099799e+05</td>\n",
       "      <td>14309.240664</td>\n",
       "      <td>0.078957</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.932972</td>\n",
       "      <td>0.858954</td>\n",
       "      <td>0.012446</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.111559</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>7.627168e+04</td>\n",
       "      <td>11818.958875</td>\n",
       "      <td>0.064049</td>\n",
       "      <td>0.002994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.924359</td>\n",
       "      <td>0.851007</td>\n",
       "      <td>0.027298</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.165212</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>3.126191e+05</td>\n",
       "      <td>13758.746803</td>\n",
       "      <td>0.125150</td>\n",
       "      <td>0.001880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.058920</td>\n",
       "      <td>0.986234</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.131013</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>1.093631e+05</td>\n",
       "      <td>9383.379934</td>\n",
       "      <td>0.094754</td>\n",
       "      <td>0.000586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.927943</td>\n",
       "      <td>0.855925</td>\n",
       "      <td>0.019867</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.140949</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>6.890213e+04</td>\n",
       "      <td>17338.209426</td>\n",
       "      <td>0.084138</td>\n",
       "      <td>0.004433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.921413</td>\n",
       "      <td>0.849393</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.098696</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>1.523651e+05</td>\n",
       "      <td>6607.779982</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.002688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.925600</td>\n",
       "      <td>0.852914</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>2.524177e+05</td>\n",
       "      <td>13017.094582</td>\n",
       "      <td>0.067936</td>\n",
       "      <td>0.003585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>1.068567</td>\n",
       "      <td>0.997215</td>\n",
       "      <td>0.019176</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>5.345651e+04</td>\n",
       "      <td>8628.735823</td>\n",
       "      <td>0.083180</td>\n",
       "      <td>0.004681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.939136</td>\n",
       "      <td>0.867451</td>\n",
       "      <td>0.023222</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.152338</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>9.962139e+04</td>\n",
       "      <td>14185.005680</td>\n",
       "      <td>0.091196</td>\n",
       "      <td>0.003352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.917892</td>\n",
       "      <td>0.846874</td>\n",
       "      <td>0.017549</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.132466</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>1.984469e+05</td>\n",
       "      <td>14590.364906</td>\n",
       "      <td>0.091239</td>\n",
       "      <td>0.002184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.934186</td>\n",
       "      <td>0.861500</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.102452</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>5.662376e+04</td>\n",
       "      <td>3990.076807</td>\n",
       "      <td>0.044518</td>\n",
       "      <td>0.002084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.931012</td>\n",
       "      <td>0.858222</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.130813</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>4.972088e+05</td>\n",
       "      <td>32368.690097</td>\n",
       "      <td>0.095624</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dense_L3_U16</td>\n",
       "      <td>0.923778</td>\n",
       "      <td>0.851092</td>\n",
       "      <td>0.016269</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.127549</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>1.682560e+06</td>\n",
       "      <td>218047.603417</td>\n",
       "      <td>0.080090</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>8.043848</td>\n",
       "      <td>7.822312</td>\n",
       "      <td>0.034842</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.186661</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>1.199604e+05</td>\n",
       "      <td>10003.129930</td>\n",
       "      <td>0.130790</td>\n",
       "      <td>0.001550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>8.553803</td>\n",
       "      <td>8.302577</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.135926</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>2.891908e+05</td>\n",
       "      <td>30156.320588</td>\n",
       "      <td>0.084132</td>\n",
       "      <td>0.003165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.596096</td>\n",
       "      <td>9.305025</td>\n",
       "      <td>0.020946</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.144726</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>6.538525e+04</td>\n",
       "      <td>6783.608442</td>\n",
       "      <td>0.077482</td>\n",
       "      <td>0.002826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.585961</td>\n",
       "      <td>9.309225</td>\n",
       "      <td>0.023611</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.153637</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>1.120320e+05</td>\n",
       "      <td>4562.167521</td>\n",
       "      <td>0.065986</td>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.821063</td>\n",
       "      <td>9.522313</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.121598</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>8.399784e+04</td>\n",
       "      <td>5949.039975</td>\n",
       "      <td>0.078531</td>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.433237</td>\n",
       "      <td>10.108335</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.144988</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>9.284055e+04</td>\n",
       "      <td>5132.222849</td>\n",
       "      <td>0.101388</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.604595</td>\n",
       "      <td>9.314773</td>\n",
       "      <td>0.020866</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.144447</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>8.890880e+04</td>\n",
       "      <td>11019.849717</td>\n",
       "      <td>0.082394</td>\n",
       "      <td>0.002419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.862503</td>\n",
       "      <td>9.558763</td>\n",
       "      <td>0.031534</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.177457</td>\n",
       "      <td>0.008053</td>\n",
       "      <td>3.459638e+04</td>\n",
       "      <td>6117.639717</td>\n",
       "      <td>0.113371</td>\n",
       "      <td>0.006483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.802432</td>\n",
       "      <td>9.513968</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.182785</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>9.198628e+01</td>\n",
       "      <td>12.169439</td>\n",
       "      <td>0.114112</td>\n",
       "      <td>0.007082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.547521</td>\n",
       "      <td>9.270302</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.119418</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>1.686744e+06</td>\n",
       "      <td>208187.657257</td>\n",
       "      <td>0.067947</td>\n",
       "      <td>0.002306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.490013</td>\n",
       "      <td>9.201434</td>\n",
       "      <td>0.015883</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.126009</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>1.014370e+05</td>\n",
       "      <td>33329.395126</td>\n",
       "      <td>0.081669</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.645222</td>\n",
       "      <td>9.370821</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.107443</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>1.020909e+05</td>\n",
       "      <td>4686.943492</td>\n",
       "      <td>0.065361</td>\n",
       "      <td>0.004560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.268017</td>\n",
       "      <td>9.949940</td>\n",
       "      <td>0.019108</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.138218</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>1.037386e+05</td>\n",
       "      <td>19787.977372</td>\n",
       "      <td>0.086417</td>\n",
       "      <td>0.002797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.173183</td>\n",
       "      <td>9.860774</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.141505</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>8.869359e+04</td>\n",
       "      <td>5977.486383</td>\n",
       "      <td>0.090766</td>\n",
       "      <td>0.002192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.088636</td>\n",
       "      <td>8.816166</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.098334</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>1.078278e+05</td>\n",
       "      <td>15401.820937</td>\n",
       "      <td>0.053588</td>\n",
       "      <td>0.002392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.269321</td>\n",
       "      <td>9.002590</td>\n",
       "      <td>0.015441</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.124256</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>9.314463e+04</td>\n",
       "      <td>15808.288012</td>\n",
       "      <td>0.078160</td>\n",
       "      <td>0.004771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.312286</td>\n",
       "      <td>9.994206</td>\n",
       "      <td>0.017808</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.133440</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>3.453294e+05</td>\n",
       "      <td>5263.339768</td>\n",
       "      <td>0.085826</td>\n",
       "      <td>0.002607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.103730</td>\n",
       "      <td>9.806659</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.122064</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>1.089739e+05</td>\n",
       "      <td>5105.820718</td>\n",
       "      <td>0.079586</td>\n",
       "      <td>0.002962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.858960</td>\n",
       "      <td>9.568348</td>\n",
       "      <td>0.013053</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.114245</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>1.207443e+05</td>\n",
       "      <td>11786.179928</td>\n",
       "      <td>0.069274</td>\n",
       "      <td>0.002799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.755573</td>\n",
       "      <td>9.456821</td>\n",
       "      <td>0.032501</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.180116</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>2.304622e+05</td>\n",
       "      <td>24636.004251</td>\n",
       "      <td>0.137657</td>\n",
       "      <td>0.008010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.019087</td>\n",
       "      <td>9.726683</td>\n",
       "      <td>0.018534</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.136135</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>1.305718e+05</td>\n",
       "      <td>10607.219976</td>\n",
       "      <td>0.099479</td>\n",
       "      <td>0.001784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.305491</td>\n",
       "      <td>9.985619</td>\n",
       "      <td>0.022903</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.151328</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>5.410743e+04</td>\n",
       "      <td>19088.628763</td>\n",
       "      <td>0.086244</td>\n",
       "      <td>0.007827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.200289</td>\n",
       "      <td>9.902166</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.101621</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>1.262740e+05</td>\n",
       "      <td>15922.253807</td>\n",
       "      <td>0.066076</td>\n",
       "      <td>0.003399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.035945</td>\n",
       "      <td>9.729447</td>\n",
       "      <td>0.008408</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.091691</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>1.903960e+05</td>\n",
       "      <td>25674.702242</td>\n",
       "      <td>0.064891</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.228079</td>\n",
       "      <td>9.926963</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.145920</td>\n",
       "      <td>0.007720</td>\n",
       "      <td>2.807344e+04</td>\n",
       "      <td>17603.283487</td>\n",
       "      <td>0.087852</td>\n",
       "      <td>0.011733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.495786</td>\n",
       "      <td>9.219285</td>\n",
       "      <td>0.028025</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.167394</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>1.236301e+05</td>\n",
       "      <td>6610.568969</td>\n",
       "      <td>0.101930</td>\n",
       "      <td>0.003398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.283620</td>\n",
       "      <td>9.971138</td>\n",
       "      <td>0.021571</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.146862</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>1.042787e+05</td>\n",
       "      <td>10722.828420</td>\n",
       "      <td>0.106130</td>\n",
       "      <td>0.001971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>9.854997</td>\n",
       "      <td>9.555230</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.103476</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>4.903854e+04</td>\n",
       "      <td>8342.004516</td>\n",
       "      <td>0.044523</td>\n",
       "      <td>0.002417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.170537</td>\n",
       "      <td>9.875401</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.147772</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>3.988970e+05</td>\n",
       "      <td>91112.174742</td>\n",
       "      <td>0.100551</td>\n",
       "      <td>0.004605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>BiLSTM_L2_U20</td>\n",
       "      <td>10.254177</td>\n",
       "      <td>9.949657</td>\n",
       "      <td>0.018260</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.135124</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>1.957792e+06</td>\n",
       "      <td>257737.276454</td>\n",
       "      <td>0.087721</td>\n",
       "      <td>0.002741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     architecture  train_time  avg_time_epoch       mse   mse_std      rmse  \\\n",
       "0    Dense_L3_U16    0.935475        0.859926  0.034367  0.000558  0.185379   \n",
       "1    Dense_L3_U16    1.062256        0.988570  0.016742  0.000258  0.129387   \n",
       "2    Dense_L3_U16    0.926651        0.854965  0.018892  0.000258  0.137447   \n",
       "3    Dense_L3_U16    0.923367        0.851295  0.022242  0.000605  0.149128   \n",
       "4    Dense_L3_U16    0.921280        0.849261  0.013165  0.000217  0.114735   \n",
       "5    Dense_L3_U16    0.922215        0.848528  0.019220  0.000138  0.138637   \n",
       "6    Dense_L3_U16    0.933126        0.859773  0.018804  0.000615  0.137116   \n",
       "7    Dense_L3_U16    0.944919        0.869899  0.023224  0.000673  0.152384   \n",
       "8    Dense_L3_U16    0.924121        0.850769  0.024089  0.001217  0.155172   \n",
       "9    Dense_L3_U16    1.082936        1.008213  0.012787  0.000257  0.113077   \n",
       "10   Dense_L3_U16    0.929922        0.855903  0.014594  0.000291  0.120801   \n",
       "11   Dense_L3_U16    0.955976        0.881290  0.009364  0.000030  0.096769   \n",
       "12   Dense_L3_U16    0.934959        0.862940  0.017601  0.000795  0.132648   \n",
       "13   Dense_L3_U16    0.922245        0.849893  0.019530  0.000174  0.139748   \n",
       "14   Dense_L3_U16    1.097445        1.023092  0.009593  0.000056  0.097945   \n",
       "15   Dense_L3_U16    0.929354        0.856337  0.013233  0.000141  0.115034   \n",
       "16   Dense_L3_U16    0.914196        0.842844  0.016357  0.000212  0.127894   \n",
       "17   Dense_L3_U16    1.065188        0.991836  0.014401  0.000088  0.120002   \n",
       "18   Dense_L3_U16    0.932972        0.858954  0.012446  0.000236  0.111559   \n",
       "19   Dense_L3_U16    0.924359        0.851007  0.027298  0.000721  0.165212   \n",
       "20   Dense_L3_U16    1.058920        0.986234  0.017166  0.000427  0.131013   \n",
       "21   Dense_L3_U16    0.927943        0.855925  0.019867  0.000108  0.140949   \n",
       "22   Dense_L3_U16    0.921413        0.849393  0.009741  0.000092  0.098696   \n",
       "23   Dense_L3_U16    0.925600        0.852914  0.007952  0.000413  0.089154   \n",
       "24   Dense_L3_U16    1.068567        0.997215  0.019176  0.000668  0.138462   \n",
       "25   Dense_L3_U16    0.939136        0.867451  0.023222  0.001491  0.152338   \n",
       "26   Dense_L3_U16    0.917892        0.846874  0.017549  0.000380  0.132466   \n",
       "27   Dense_L3_U16    0.934186        0.861500  0.010497  0.000230  0.102452   \n",
       "28   Dense_L3_U16    0.931012        0.858222  0.017116  0.000587  0.130813   \n",
       "29   Dense_L3_U16    0.923778        0.851092  0.016269  0.000142  0.127549   \n",
       "30  BiLSTM_L2_U20    8.043848        7.822312  0.034842  0.000171  0.186661   \n",
       "31  BiLSTM_L2_U20    8.553803        8.302577  0.018476  0.000147  0.135926   \n",
       "32  BiLSTM_L2_U20    9.596096        9.305025  0.020946  0.000203  0.144726   \n",
       "33  BiLSTM_L2_U20    9.585961        9.309225  0.023611  0.000952  0.153637   \n",
       "34  BiLSTM_L2_U20    9.821063        9.522313  0.014790  0.000569  0.121598   \n",
       "35  BiLSTM_L2_U20   10.433237       10.108335  0.021022  0.000217  0.144988   \n",
       "36  BiLSTM_L2_U20    9.604595        9.314773  0.020866  0.000316  0.144447   \n",
       "37  BiLSTM_L2_U20    9.862503        9.558763  0.031534  0.002854  0.177457   \n",
       "38  BiLSTM_L2_U20    9.802432        9.513968  0.033448  0.002757  0.182785   \n",
       "39  BiLSTM_L2_U20    9.547521        9.270302  0.014262  0.000319  0.119418   \n",
       "40  BiLSTM_L2_U20    9.490013        9.201434  0.015883  0.000681  0.126009   \n",
       "41  BiLSTM_L2_U20    9.645222        9.370821  0.011565  0.001211  0.107443   \n",
       "42  BiLSTM_L2_U20   10.268017        9.949940  0.019108  0.000619  0.138218   \n",
       "43  BiLSTM_L2_U20   10.173183        9.860774  0.020024  0.000322  0.141505   \n",
       "44  BiLSTM_L2_U20    9.088636        8.816166  0.009670  0.000136  0.098334   \n",
       "45  BiLSTM_L2_U20    9.269321        9.002590  0.015441  0.000406  0.124256   \n",
       "46  BiLSTM_L2_U20   10.312286        9.994206  0.017808  0.000486  0.133440   \n",
       "47  BiLSTM_L2_U20   10.103730        9.806659  0.014900  0.000097  0.122064   \n",
       "48  BiLSTM_L2_U20    9.858960        9.568348  0.013053  0.000247  0.114245   \n",
       "49  BiLSTM_L2_U20    9.755573        9.456821  0.032501  0.003369  0.180116   \n",
       "50  BiLSTM_L2_U20   10.019087        9.726683  0.018534  0.000402  0.136135   \n",
       "51  BiLSTM_L2_U20   10.305491        9.985619  0.022903  0.000573  0.151328   \n",
       "52  BiLSTM_L2_U20   10.200289        9.902166  0.010328  0.000300  0.101621   \n",
       "53  BiLSTM_L2_U20   10.035945        9.729447  0.008408  0.000125  0.091691   \n",
       "54  BiLSTM_L2_U20   10.228079        9.926963  0.021332  0.002287  0.145920   \n",
       "55  BiLSTM_L2_U20    9.495786        9.219285  0.028025  0.000885  0.167394   \n",
       "56  BiLSTM_L2_U20   10.283620        9.971138  0.021571  0.000536  0.146862   \n",
       "57  BiLSTM_L2_U20    9.854997        9.555230  0.010709  0.000384  0.103476   \n",
       "58  BiLSTM_L2_U20   10.170537        9.875401  0.021841  0.000730  0.147772   \n",
       "59  BiLSTM_L2_U20   10.254177        9.949657  0.018260  0.000427  0.135124   \n",
       "\n",
       "    rmse_std          mape       mape_std       mae   mae_std  \n",
       "0   0.001503  8.435151e+04    5276.563581  0.134481  0.001163  \n",
       "1   0.000998  2.894397e+05   17633.278160  0.076471  0.001340  \n",
       "2   0.000939  4.547944e+04    6384.431282  0.076337  0.000670  \n",
       "3   0.002022  1.328210e+05    7263.428431  0.063521  0.000920  \n",
       "4   0.000947  8.575916e+04    7781.146682  0.073596  0.001301  \n",
       "5   0.000497  1.000368e+05    8598.919788  0.100257  0.002861  \n",
       "6   0.002232  7.152170e+04    6090.935211  0.081467  0.001777  \n",
       "7   0.002216  1.423177e+04    6381.654232  0.098019  0.000635  \n",
       "8   0.003905  6.658551e+01       8.269819  0.090012  0.001159  \n",
       "9   0.001139  2.638208e+06  370528.215327  0.069678  0.004041  \n",
       "10  0.001202  9.364932e+04   13583.632441  0.078773  0.001619  \n",
       "11  0.000153  1.150177e+05    5418.352843  0.065870  0.001539  \n",
       "12  0.002977  1.269672e+05   20737.326466  0.086731  0.001703  \n",
       "13  0.000622  7.681692e+04     845.380460  0.092276  0.004179  \n",
       "14  0.000287  1.255156e+05    4264.534923  0.057032  0.001594  \n",
       "15  0.000611  7.891706e+04   13231.180554  0.073675  0.005404  \n",
       "16  0.000827  1.924626e+05   19453.339047  0.082780  0.002167  \n",
       "17  0.000367  1.099799e+05   14309.240664  0.078957  0.002105  \n",
       "18  0.001054  7.627168e+04   11818.958875  0.064049  0.002994  \n",
       "19  0.002182  3.126191e+05   13758.746803  0.125150  0.001880  \n",
       "20  0.001622  1.093631e+05    9383.379934  0.094754  0.000586  \n",
       "21  0.000385  6.890213e+04   17338.209426  0.084138  0.004433  \n",
       "22  0.000467  1.523651e+05    6607.779982  0.061127  0.002688  \n",
       "23  0.002297  2.524177e+05   13017.094582  0.067936  0.003585  \n",
       "24  0.002405  5.345651e+04    8628.735823  0.083180  0.004681  \n",
       "25  0.004852  9.962139e+04   14185.005680  0.091196  0.003352  \n",
       "26  0.001440  1.984469e+05   14590.364906  0.091239  0.002184  \n",
       "27  0.001127  5.662376e+04    3990.076807  0.044518  0.002084  \n",
       "28  0.002250  4.972088e+05   32368.690097  0.095624  0.001779  \n",
       "29  0.000556  1.682560e+06  218047.603417  0.080090  0.000898  \n",
       "30  0.000458  1.199604e+05   10003.129930  0.130790  0.001550  \n",
       "31  0.000542  2.891908e+05   30156.320588  0.084132  0.003165  \n",
       "32  0.000701  6.538525e+04    6783.608442  0.077482  0.002826  \n",
       "33  0.003082  1.120320e+05    4562.167521  0.065986  0.002400  \n",
       "34  0.002353  8.399784e+04    5949.039975  0.078531  0.002284  \n",
       "35  0.000750  9.284055e+04    5132.222849  0.101388  0.000544  \n",
       "36  0.001093  8.890880e+04   11019.849717  0.082394  0.002419  \n",
       "37  0.008053  3.459638e+04    6117.639717  0.113371  0.006483  \n",
       "38  0.007485  9.198628e+01      12.169439  0.114112  0.007082  \n",
       "39  0.001335  1.686744e+06  208187.657257  0.067947  0.002306  \n",
       "40  0.002688  1.014370e+05   33329.395126  0.081669  0.003333  \n",
       "41  0.005566  1.020909e+05    4686.943492  0.065361  0.004560  \n",
       "42  0.002248  1.037386e+05   19787.977372  0.086417  0.002797  \n",
       "43  0.001137  8.869359e+04    5977.486383  0.090766  0.002192  \n",
       "44  0.000693  1.078278e+05   15401.820937  0.053588  0.002392  \n",
       "45  0.001628  9.314463e+04   15808.288012  0.078160  0.004771  \n",
       "46  0.001827  3.453294e+05    5263.339768  0.085826  0.002607  \n",
       "47  0.000396  1.089739e+05    5105.820718  0.079586  0.002962  \n",
       "48  0.001079  1.207443e+05   11786.179928  0.069274  0.002799  \n",
       "49  0.009430  2.304622e+05   24636.004251  0.137657  0.008010  \n",
       "50  0.001478  1.305718e+05   10607.219976  0.099479  0.001784  \n",
       "51  0.001885  5.410743e+04   19088.628763  0.086244  0.007827  \n",
       "52  0.001478  1.262740e+05   15922.253807  0.066076  0.003399  \n",
       "53  0.000683  1.903960e+05   25674.702242  0.064891  0.001800  \n",
       "54  0.007720  2.807344e+04   17603.283487  0.087852  0.011733  \n",
       "55  0.002632  1.236301e+05    6610.568969  0.101930  0.003398  \n",
       "56  0.001826  1.042787e+05   10722.828420  0.106130  0.001971  \n",
       "57  0.001848  4.903854e+04    8342.004516  0.044523  0.002417  \n",
       "58  0.002459  3.988970e+05   91112.174742  0.100551  0.004605  \n",
       "59  0.001586  1.957792e+06  257737.276454  0.087721  0.002741  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_csv(f'evaluations/clustered_federated_learning/{architecture}.csv')\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
