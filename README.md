# Attacks-and-Security-of-Federated-Learning

> **Abstract:**
> Efficient prediction of short-term energy consumption in homes is essential for the development of smart grids and requires the exploration of advanced techniques such as deep neural networks. However, the traditional approach of centralising data for model training raises privacy concerns. Decentralised solutions, in particular federated learning (FL), have emerged to address this, but they are not immune to security threats. This research addresses the vulnerabilities and security risks associated with FL in short-term load forecasting, exploring existing security measures and proposing a focus on GAN-based attacks. The study reviews the relevant literature, conducts an in-depth analysis of GAN attacks, evaluates security measures such as noise and differential privacy, and implements and evaluates GAN attacks on real datasets to improve the robustness of FL models. The contribution lies in identifying defensive measures to strengthen the security and privacy of FL models, with a particular focus on mitigating GAN attacks in the context of short-term load forecasting.
